\documentclass[11pt]{article}

\usepackage[justification=centering]{caption}
\usepackage[a4paper, total={6.5in, 9in}]{geometry}
\emergencystretch=1em
\usepackage{titling}
\setlength{\droptitle}{8em}
\usepackage{xurl}
\usepackage{lineno}
\usepackage[skip=0pt,font=scriptsize]{caption} 
\usepackage[labelfont=bf, justification=justified]{caption}
\usepackage{graphicx}
\usepackage{pgfplotstable,booktabs}
\usepackage{array,ragged2e}
\usepackage{multirow}
\pgfplotsset{compat=1.16}
\usepackage{setspace}
\usepackage[sorting=nyt,style=apa]{biblatex}
\usepackage{booktabs}

\bibliography{library.bib}

% titles:
% Discerning Ancestry-Based Assortative Mating from Migration by their Genomic Imprint upon Admixed Populations of the Americas
\title{Discerning Ancestry-Based Assortative Mating from Migration by their Genomic Imprint upon Admixed Populations of the Americas}
\author{\\ \\ \\ \\ Ben Nouhan, bjn20@ic.ac.uk \\ \\ Imperial College London \\}
\date{\today}
\newcommand\wordcount{\input{report.sum}}


% general instructions
% • Structure and Style:
% All reports should have an Abstract, Introduction, Methods, Results, Discussion and possibly, a separate Conclusions section. Do not format your report to look like a paper from a specific journal.
% • Word limit:
% The main text should not exceed 6,000 words in length (excluding figures, tables, references and appendices/supplementary information). Using the full 6,000 words is often not advisable – this is an absolute maximum. Clarity and brevity are better than wordiness, so do not puff up your thesis to reach 6,000 words. More instructions on content are provided below. You must not abuse the exclusion of figure and table legends from the word count to squeeze in more material. They must only explain the contents of the figure or table!
% • Figure Limit:
% Most journals have an upper limit of the total number of figures and tables – it is rare to see more than a total of about 6 – 8 figures and tables (not 6 – 8 of each!). We would like you to try and keep under a total of 8 figures and tables. If you have more than this, then think carefully about whether they are all crucial to helping the reader understand your research. If they are, then include them; if not, then move them to supplementary material. Published papers often use complex multipart figures to reduce figure counts. Bringing related figures and tables together is good practice, but is often very time consuming and fiddly. You should prioritize making your selected figures and tables as clear and informative as possible: do not spend time and effort merging figures unless you are sure you have nothing else left to do!
% • Font:
% You should use a ‘normal’ font at 11 point or 12 point size. We recommend Helvetica, Arial or Times New Roman – similar fonts are also fine. Do not use highly stylized or bitmap fonts. You may have any number of references, but note that excessive referencing will be as frowned upon as inadequate referencing!
% The main body of the text should use 1.5 line spacing and page numbering should be used.
% The thesis margins should be at least 2 cm and the main text font size should not be smaller than 11 point.








\begin{document}




\vspace{30mm}
\maketitle
\thispagestyle{empty}

\vspace{5mm}
\centerline{Word Count: \wordcount}

\vspace{15mm}
\onehalfspacing
\renewcommand{\abstractname}{\vspace{-\baselineskip}} %hide abstract title

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Abstract %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% NB: follow the usual thing for this, from nature - best resource I reckon
\begin{abstract}
    \linenumbers
    \noindent
    \textbf{The ability to understand and predict population growth is vital for multiple disciplines. Technology is increasingly enabling us to model large datasets, uncover the insights buried within them, and improve the models iteratively. Scaling up this process to ingest more data and quantify improvements to the models would push forward our capabilities and inform future research. Here I showcase a prototypal pipeline to fit established models to hundreds of datasets, quantify their performance for comparison between them, and use control variable data to glean insights out of this process. Consistent with the literature, the methodology proclaimed the Gompertz model as the highest-performing of those tested, while highlighting its flaws. Correlating performance of the models and separately the morphology of their resultant fits with potential covariables has the potential to improve or even inspire subsequent investigation. Meanwhile the pipeline as a whole can, with modest alterations, be used on groups of models from a multitude of fields, at best facilitating the development of the very models it upon which it is used to analyse and elucidate.
    }
\end{abstract}
\vspace{10mm}


\newpage
\tableofcontents
\thispagestyle{empty}

\newpage
\linenumbers

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Introduction %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\setcounter{page}{1}
\section{Introduction}
% A good introduction should leave the reader with a clear idea of the problem to be tackled and looking forward to the more detailed sections to follow.
% It should include a section on the general way the problem has been approached. 
% An essential concluding part of the introduction is to clearly define the aims of the research project and any hypotheses tested.
% Also, think about:
%  o What is this paper about? (i.e., the broad area, big picture) Why is that interesting?
%  o Given it’s so interesting, why don’t we know the answer?
%  o So, what is this about, more specifically? What are hypothesised to be the important things? Build from the most general and fundamental hypotheses to the most refined or tenuous ones.
%  o How, roughly and briefly, will you go about testing these hypotheses? Why are you using this system? What approach will you use?
%  o State clearly what your hypotheses are.

History and background of pop genetics (perhaps specifically study of mating patterns)

background of assortative mating and pop structure, significance

sociologogical background of the region, eg SA colonialism, slavery effective, why it's a good case study

assortative mating by social structures eg wealth, status, etc in the region - have claims that it exists be made?

genetic markers telling us about ancestry (assuming that's how RFMix works)



neural networks

use of neural networks on these markers/windows/whatever



Aims of paper






1000ish words should be good, 1500 absolute max



From proposal: 

intro
Certain genetic phenomena, including assortative mating and sex bias, have the potential to alter the structure of human populations.  This in turn modifies genomic variation, reflected in a population’s genomic data which can be used to infer said phenomena.  Various factors,  cultural or socio-economic, can cause them to arise or to manifest themselves.  Historically, the social stratification of societies by wealth, power and perceived race, alongside explicit racial segregation policies, have modulated human mating behaviour away from random mating. In  the  past  century,  the geopolitical  and  economic  landscape  has  experienced  and  will  continue to experience intercontinental migration towards areas of high population density, engendered by the  likes  of  globalization,  industrialisation,  shifting  demographics,  the  fallout  of  colonialism  and global  warming.   This  mass  migration  occurring  within  a  relatively  small  timescale  has  founded new, diverse societies with complex and stratified urban population structures.The  modern  era  is  not  the  first  in  which  this  has  occurred,  indeed  the  convoluted  layers  ofancient processes of migration and subsequent admixture,  which shaped populations around theworld  over  millennia,  are  shown  to  have  been  sex-biased  in  many  cases,  and  may  additionallyhave been impacted by localised assortative mating patterns.(Goldberg et al., 2014; Skoglund and Mathieson, 2018) This project seeks to utilise deep learning algorithms and widely available genomic data in theelucidation of how complex human mating behaviours have been effected by both social and eco-nomic conditions, which stem from the genetic structure of different historic and current admixingpopulations.(Sheehan and Song, 2016)

Outcome
The project’s outcome will be in two forms.  I will be comparing the efficacy of the different neuralnetwork combinations outlined above based on their accuracy estimating multiple parameters.  Iwill then be using highest-performing method to infer parameters, such as assortative mating andsex bias, from genomic data and ultimately integrate my findings into the phenotypic and culturallandscape of the studied region.













Understanding population growth is paramount in fields of study as far-flung as epidemiology, climate science and geopolitics.\parencite{Ozgul2010,Peleg1997} For decades, increasingly complex mathematical models have been used to explain trends in empirical population growth time series and enable prediction.\parencite{Kingsland1982,Grijspeerdt1999,Tjørve2017} Fewer parameters reduce the chance of models overfitting the data and hence, using bacterial growth as an example, variables not included such as incubation temperature, bacterial strain and growth medium should be kept constant.

Bacterial growth models largely rely on the theory of bacterial growth phases in a closed system, shown schematically in \textbf{Figure 1}. There are four accepted phases: the lag phase, exponential growth phase, stationary phase and death phase, with some considering the three transition periods between them as additional phases in their own right.\parencite{Buchanan1918}


% \vspace{5mm}
% \begin{figure}[htb]
%     \centering
%     \includegraphics[width=0.45\textwidth]{../results/figures/growth.pdf}
%     \caption{\textbf{Schematic example of an archetypal bacterial growth curve demonstrating the four phases of growth.}  The lag phase is the initial period of zero or minimal growth whereby the bacteria, having been transferred to a new medium, require time to acclimatise. For example, the new environment may impact gene expression and hence the bacteria's replication machinery are not immediately operational.\parencite{Buchanan1918} During the exponential growth phase, characterised by an exponential curve owing to the rate of increase per bacterium remaining constant, the bacteria can continuously multiply absent limiting environmental factors.\parencite{Micha2011} The stationary phase, a population plateau completing the sigmoidal shape of the growth curve, arises due to the population reaching the carrying capacity of the medium; rate of division approximately equals the death rate.\parencite{Buchanan1918} In some instances there is a subsequent death phase, during which death rate surpasses the rate of division due to factors such as the accumulation of a toxic substance or depletion of the medium.\parencite{Micha2011, Buchanan1918}
%     The first three phases in the above chart were generated from the dataset used throughout this study (specifically, Pseudomonas spp. grown on raw chicken breast at 2°C) with a regression line fit using the Gompertz model. The "death phase" was appended artificially.}
% \end{figure}
% \vspace{5mm}

Technological advancements since the 1990s have caused the quantity of data generated from biological experiments, the speed at which computers analyse them and the accessability of the process to skyrocket. This allowed life scientists to mathematically model natural phenomena in ways previously limited to the physical sciences.\parencite{Bolker2013,Johnson2004} These can be linear models (LMs), wherein the response variable 'y' has a linear relationship with the parameters if not the explanatory variable 'x' as in \textbf{Equation 1}; or non-linear models (NLMs), wherein the response variable has a non-linear relationship with a parameter and the explanatory variable as in \textbf{Equation 2}.\parencite{Bolker2013} Regardless of whether these models truly represent the natural laws in question, they are undoubtedly useful for prediction phenomena, and the development of more sophisticated models.\parencite{Transtrum2016}

\begin{equation}
    y = a + bx + cx\textsuperscript{2}
\end{equation}

\begin{equation}
    y = a + bx\textsuperscript{c}
\end{equation}
\vspace{2mm}

Parameters of some NLMs for population growth, such as the logistic, Gompertz, Baranyi and Buchanan models, can be related to the aforementioned phases. These include: t\textsubscript{lag}, the duration of the lag phase; N\textsubscript{0}, the minimum population that can feasibly lead to growth; N\textsubscript{max}, the maximum population the system can feasibly support; and r\textsubscript{max}, the maximum possible growth rate.\parencite{Micha2011} It has been asserted that without parameters like these based firmly in scientific theory an equation used to fit data is not truly a model.\parencite{Buchanan1997}

  

The logistic model, \textbf{Equation 3}, is one of the oldest population growth models and is still used in fields from medicine to economics. It was initially posited as a model for human population growth in which the growth rate per unit decreases as the sample population approaches N\textsubscript{max}.\parencite{Peleg1997} Many newer, more sophisticated population growth models were derived from the logistic model, but introduce the t\textsubscript{lag} parameter which increases their utility when fit to timeseries with a lag phase.

\begin{equation}
    N_{t} = \frac{ N_{0} . N_{max} . e^{t . r_{max}}      }
                 { N_{max} + N_{0} . (e^{t . r_{max}} - 1)}
\end{equation}
\vspace{3mm}



The modified Gompertz model incorporates biologically meaningful parameters into an empirical, sigmoidal relationship.\parencite{Tjørve2017, Buchanan1997} First conceived for predicting mortality rates in human populations, countless studies in various disciplines have utilised it.\parencite{Tjørve2017, Buchanan1997, Mokhtari2019, Peleg1997} One form of it, shown by \textbf{Equation 4}, includes the t\textsubscript{lag} parameter, thereby incorporating the lag phase absent in the logistic model.\parencite{Zwietering1990,Buchanan1997}

\begin{equation}
    N_{t} = N_{max} . e^{-e^{\frac{ e . r_{max}   }
                                  { N_{max}-N_{0} } . (t_{lag} - t) + 1}}
\end{equation}
\vspace{3mm}



The Baranyi model, first published in 1993, is a logistic rate differential equation designed specifically for modelling bacterial growth curve dynamics.\parencite{Baranyi1993,Buchanan1997} The theory of a "bottleneck" chemical reaction limiting the maximum growth rate, r\textsubscript{max}, underpins the model.\parencite{Buchanan1997} Alongside the Gompertz model it has overtaken the logistic model in popularity for modelling population growth, owing in part to the t\textsubscript{lag} parameter that can be derived from the original equation: \textbf{Equation 5} represents the baranyi model rearranged to include the parameters discussed herein.

\begin{equation}
    N_{t} = N_{max} - ln{(1 + (e^{-N_{max} - N_{0}} - 1) . e^{-r_{max} . t_{lag}})}
\end{equation}
\vspace{3mm}



The Buchanan model can be thought of as a three-phase linear model, demonstrated by \textbf{Equation 6}.\parencite{Buchanan1997} It was proposed in 1997 to determine how accurately bacterial growth timeseries could be modelled by a simpler model to those of Gompertz and Baranyi. It requires a parameter t\textsubscript{max}, the time at which N\textsubscript{max} is first reached, which can be estimated from N\textsubscript{max} itself. Its first phase exhibits zero growth until approximately t\textsubscript{lag}, preceding a period of linear r\textsubscript{max} growth, until the population plateaus at t\textsubscript{max}.\parencite{Buchanan1997}

\begin{equation}
    N_{t} = \left\{
    \begin{array}{l}
        N_{0}                   \hspace{43mm}    for \           t \le t_{lag}\\
        N_{max} + r_{max} * (t - t_{lag}) \qquad for \ t_{lag} < t  <  t_{max}\\
        N_{max}                 \hspace{38.5mm}  for \           t \ge t_{max}\\
    \end{array}\right\}
\end{equation}
\vspace{5mm}



Modelling is seen by some as the successor of classical hypothesis testing, and by others as another tool in their arsenal.\parencite{Johnson2004} Since multiple models can be employed for the same task, the ability to determine which model is most useful in a given situation is a science in of itself. The Bayesian information criterion (BIC) is one metric for model selection, which is defined in \textbf{Equation 7}. It assigns each model a score derived from the sample size used, n, the maximum likelihood estimation of the model, L, and the number of parameters, k; models with fewer parameters are generally more stable by reducing inter-parameter correlation.\parencite{Akaike1974,Zwietering1990} The lower the score, the better the model; a difference in score between models of less than two is considered insignificant, and greater than ten highly significant.\parencite{Vrieze2012,Posada2004}. An alternative is Akaike information criterion (AIC) which, while derived from frequentist probability rather than Bayesian, is largely the same except confers a smaller penalty for additional parameters.\parencite{Posada2004} 
\begin{equation}
    BIC = k.log(n) - 2.log(L)
\end{equation}
\vspace{2mm}

\noindent While BIC scoring can inform on the relative performance of multiple models on a given dataset, there is no established method for doing this across multiple datasets. Thus my objectives with this study are three-fold: to design a general, robust methodology for the high-throughput fitting of multiple population growth models, linear and non-linear, to a large quantity of datasets; to further design a method for selecting the overall best model, determined as a function of both accuracy and consistency; and to visualise the results in a way that will highlight correlations between covariables of the datasets and performance of the models or the growth behaviour. The latter may reveal whether certain models may be more appropriate for experiments executed under certain conditions, or if said conditions alter the underlying mechanism being modelled, facilitating the conception of hypotheses for subsequent experimentation.





















%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Methods %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{5mm}
\section{Methods}

% This should contain details of any methods used extensively during the project, layout of field experiments, theoretical methods, methods of statistical analyses etc.
% You can use subheadings for different procedures or tests.
% If field work is done, a general description of the study area may be included here.
% Extra methodological details can be placed in appendices.
% The golden rule is that the reader should be able to repeat what you did, should they so wish.
% The other rule -- more important for your project than in a paper -- is that you describe in enough detail to show you’ve understood what you did.
% You should feel free to use subheadings in your methods and results to help organise different parts of your project.
% If so, keep the same order of the different parts of the project in all of your sections: the methods for testing each hypothesis and the results of those tests are described in the same order as the hypotheses are described in the introduction.

% Also, think about:
% o What is the overall design of the study?
% o What are the variables and how do they relate to the hypotheses?
% o How did you get the data?
% o What are the characteristics of the data set / experiment -- how many observations, how many replicates etc.
% o General procedures, if any, that are true in all of the analyses (e.g., transformation of data, model checking, how models were compared)
% o How did you test the hypotheses, in the logical order outlined in the introduction (i.e., from the general to the specific)? Make sure you show that your tests are appropriate.

% Computer Programs. If the program has been published, cite the reference, include it in the reference list and provide a brief outline of the methods it uses.
% If you are using a program or code generated for the project then a more complete description is needed in the main text.
% You should provide the code used in an appendix and consider providing a flow chart and usage notes to help interpretation.
% You should take care to define all the input variables used in the program.


\subsection{Studied Populations}

For the initial analyses, all African, European and American populations from the 1000 Genomes Project (1KGP) and the Human Genome Diversity Project (HGDP) were used \textbf{(Table 1)}, with the exception of the Russian and Finnish populations. These were excluded owing to minimal colonial-era migration to the Americas from these populations, alongside the genetic similarities between these populations, Siberans and, by extension, Native Americans.



\begin{table}[htb]
    \centering
    \caption{
        \textbf{Details of the populations used throughout this study.} 
        Populations abbreviated as three capitalised letters are from the 1000 Human Genome Project dataset, while full-word abbreviated populations are from the Human Genome Diversity Project dataset. The number of samples used from each population is denoted by "n". \\
        **The Tuscan and Yoruba populations comprise samples from both datasets.
        }
    \small
    \begin{tabular}{ |p{3cm}||p{8cm}|p{3cm}|p{0.8cm}|  }
    \hline
    \multicolumn{1}{|c||}{\textbf{Superpopulation}} &
    \multicolumn{1}{c|}{\textbf{Population}} & 
    \multicolumn{1}{c|}{\textbf{Abbreviation}} & %vline missing here on purpose
    \multicolumn{1}{c|}{\textbf{n}}\\
    \hline
    \hline
    \multirow{6}{*}{Admixed}  %num == number of cols included
        &African Ancestry in Southwest USA & ASW & 61 \\
        &African Caribbean in Barbados & ACB & 96 \\
        &Colombian in Medellin, Colombia & CLM & 94 \\
        &Mexican Ancestry in Los Angeles, California & MXL & 64 \\
        &Peruvian in Lima, Peru & PEL & 85 \\
        &Puerto Rican in Puerto Rico & PUR & 104 \\
        \hline
    \multirow{11}{*}{African}
        &Bantu in Kenya & BantuKenya & 11 \\
        &Bantu in South Africa & BantuSouthAfrica & 8 \\
        &Biaka in Central African Republic & Biaka & 22 \\
        &Esan in Nigeria & ESN & 99 \\
        &Gambian in Western Division, The Gambia & GWD & 113 \\
        &Luhya in Webuye, Kenya & LWK & 99 \\
        &Mandenka in Senegal & Mandenka & 22 \\
        &Mbuti in Democratic Republic of Congo & Mbuti & 13 \\
        &Mende in Sierra Leone & MSL & 85 \\
        &San in Namibia & San & 6 \\
        &Yoruba in Nigeria & YRI/Yoruba* & 129 \\
    \hline
    \multirow{9}{*}{European}
        &Basque in France & Basque & 23 \\
        &Bergamo Italian in Bergamo, Italy & BergamoItalian & 12 \\
        &British in England and Scotland & GBR & 91 \\
        &Northern and Western European Ancestry in Utah & CEU & 99 \\
        &French in France & French & 28 \\
        &Orcadian in Orkney & Orcadian & 15 \\
        &Sardinian in Italy & Sardinian & 28 \\
        &Iberian in Spain & IBS & 107 \\
        &Toscani in Italy & TSI/Tuscan* & 115 \\
    \hline
    \multirow{5}{*}{Native American}
        &Colombian in Colombia & Colombian & 7 \\
        &Karitiana in Brazil & Karitiana & 12 \\
        &Maya in Mexico & Maya & 21 \\
        &Pima in Mexico & Pima & 13 \\
        &Surui in Brazil & Surui & 8 \\
    \hline
    \end{tabular}
\end{table}






\subsection{Sample \& SNP Filtering with BCFtools}

Once downloaded, the 30x coverage 1KGP and high-coverage HGDP datasets were merged, and all populations except those listed in \textbf{(Table 1)} were removed. All C→G, G→C, A→T and T→A SNPs were filtered out as they are harder to align and are hence prone to error. SNPs were further filtered with a minor allele frequency threshold of 5\%, as to reduce the dataset and remove rare and thus uninformative SNPs. Following this, all 22 filtered VCF files, one per somatic chromosome, were indexed for phasing using BCFtools.



\subsection{Genome Phasing with SHAPEIT4}





\subsection{Sample Filtering with PLINK \& ADMIXTURE}





\subsection{Local-Ancestry Inference with RFMix2}




\subsection{Assortative Mating Index Calculation}



\subsection{Genomic Window Length Analysis}




\subsection{Timeline of Admixture Estimation with TRACTS}


















%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Results %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Results}

% Describe your results in a logical order: this may not necessarily be the order in which you did the experiments.
% Briefly summarise the main results at the end of each main experiment or sequence of associated experiments.
% Do not duplicate results -- put a table or a graph but not both unless the two methods of presentation demonstrate different points of importance.
% You must refer appropriately to figures or tables in the text and remember to emphasise and perhaps quote significant results.

% In particular, think about:
% o What were the results of your hypothesis tests, in the order you describe them in the Methods?




% Figures:
% You should prepare figures to the same standard required for publication.
% All journals provide advice on preparing figures for publication, so do look at the advice to authors pages for your chosen journal.
% All figures must be numbered and have a caption that is sufficiently detailed to explain the main features of the content by itself.
% All figures must be referred to in the main text of the thesis.
% Put the figures in appropriate points in the text, close to the text that refers to them.

% In particular:
% o The resolution of your figures is crucial. For plots, try to use vector image formats (exported as svg, pdf, or eps) and not bitmapped (raster) formats like JPG and TIFF. Standard /LaTex documents typically allow *.eps or *.pdf figures to be inserted. Using the freely available (and very capable!) vector graphics program Inkscape to ``fine-tune'' your figures is often a good idea.
% Inkscape will also allow svgs to be exported in a /LaTex compatible format (see the Inkscape documentation). For RASTER graphics, the freely available GIMP editor works very well.
% o When using Word, figures in Windows Metafile format are the most reliable vector format. For Word 2011 on Mac, figures in PDF format should give a good result. If you do have to use bitmaps, make sure they are at a high resolution (300 dpi or more) -- this can be particularly important if you need to present line drawings or photographs of specimens or equipment.
% o Plots are all about the data, so reduce margins and maximise the space in the figure for showing the data.
% o Create the figure at the right size -- when it is included in your thesis are all the axis labels and text going to be clearly legible.
% o Avoid `chartjunk' (google Edward Tufte!) -- and avoid superfluous lines, legends and titles along with 3D effects.

% Tables:
% Each table should be numbered, have a full descriptive caption and again must be referred to in the main text.
% Column headings should state units of measurement.
% Avoid large, complicated tables in the main thesis and if you have a large body of numerical data put it in an appendix.







\subsection{Model Fitting}

After excluding the small datasets, 290 timeseries remained. For each of these, fits were successfully generated with all eight models, save for the Buchanan model failing to fit three. However, a successful fit does not imply a close fit, as demonstrated by \textbf{Figure 2}. 


% \begin{figure}[htb!]
%     \centering
%     \includegraphics[width=\textwidth]{../results/figures/8plots.pdf} 
%     \caption{\textbf{Exemplary timeseries plotted with the regression line that each model fit to them.}  Plots showing log\textsubscript{2} of the population measurements against time in hours, which demonstrate to what extent each model can tolerate peculiar datsets. Linear models fit datsets comprising very few datapoints with near-perfect accuracy, yet without describing the true relationship at all (top left). Timeseries with a death phase and/or no lag phase are modelled poorly by the NLMs which plateau prematurely, although the logistic model benefits from a lack of lag phase (top right). For timeseries with lag phases but which had not plateaued when measurement ceased due to a drawn-out transition between exponential and stationary phases, logistic fails to capture the lag phase and Buchanan simply plateaus at the final datapoint, while Baranyi and Gompertz plateau harshly at the start of the transition, the latter to a lesser extent (bottom).}
% \end{figure}


\subsection{Model Comparison}

The results of analyses comparing relative model performance, outlined in Section 2.4, are shown in \textbf{Table 1}. The quartic model achieved the best score in all categories, following a clear correlation of higher-order LMs performing better across the board. The logistic model performed similarly to the quadratic, while the other NLMs placed between the cubic and quartic LMs. 

Similar analyses comparing only the four NLMs, shown in \textbf{Table 2}, prevent potentially higher-performing but biologically unsubstantial LMs from masking the results of the more meaningful NLMs. Here the Gompertz model is the clear winner, top in six out of seven metrics, narrowly losing to Baranyi on mean BIC value. Baranyi performed similarly, drawing with Gompertz on win count. The Buchanan model performed worse on all counts than Baranyi, as did the logistic model, trailing significantly, compared to the Buchanan model. 

% \begin{table}[htb]
%     \centering
%     \caption{\textbf{Results of analysis comparing the fits for all 290 timeseries produced by each model}}
%     \pgfplotstabletypeset[
%     col sep = comma, font=\footnotesize,
%     every head row/.style={before row=\toprule,after row=\midrule},
%     every last row/.style={after row=\bottomrule},
%     display columns/0/.style={string type,column name={Model},column type={r}},
%     display columns/1/.style={string type,column name={Mean R\textsuperscript{2}}},
%     display columns/2/.style={string type,column name={Median R\textsuperscript{2}}}
%     ]{../results/tables/ALLstatistics.csv}
% \end{table}


% \begin{table}[htb]
%     \centering
%     \caption{\textbf{Results of analysis comparing the fits for all 290 timerseries produced by each NLM}}
%     \pgfplotstabletypeset[
%     col sep = comma, font=\footnotesize,
%     every head row/.style={before row=\toprule,after row=\midrule},
%     every last row/.style={after row=\bottomrule},
%     display columns/0/.style={string type,column name={Model},column type={r}},
%     display columns/1/.style={string type,column name={Mean R\textsuperscript{2}}},
%     display columns/2/.style={string type,column name={Median R\textsuperscript{2}}}
%     ]{../results/tables/NLMstatistics.csv}
% \end{table}


\subsection{Model-Covariable Correlation}

The first of two figures reported here for the visualisation of patterns relating to the covariables of each experiment is \textbf{Figure 3}. The method behind it seeks to reveal if certain experimental conditions systematically affect the morphology of bacterial growth curves generated by one of the three highest-performing NLMs and, by extension, bacterial growth behaviours.

In contrast, \textbf{Figure 4} is the visualisation of an attempt to correlate individual model performance with different covariable categories. The idea is to suggest if one NLM may be more appropriate than another when modelling experimental data collected under certain conditions.


% \begin{figure*}
%     \centering
%     \includegraphics[width=\textwidth]{../results/figures/multiplots.pdf} %may need to reduce height to make room for caption
%     \caption{\textbf{Standardised, superimposed growth curves for the Gompertz, Baranyi and Buchanan models, coloured by covariable category.}  Each fit of the three models was standardised in several steps. Firstly, lag phases and plateaus were removed, estimated as t\textsubscript{lag} and 95\% of N\textsubscript{max} respectively. The resulting curves were transformed to start at the origin, all population values were divided by the highest remaining population value, and all time values by the highest remaining time value. Three copies of these normalised superimposed regression lines of Gompertz, Baranyi and Buchanan (rows 2-4 respectively) are colourised by categories of the three covariables. The barcharts displayed in row 1 show the abundancies of each category out of the 256 datasets, the bar colours corresponding to the regression lines beneath them.}
% \end{figure*}


% \begin{figure*}
%     \centering
%     \includegraphics[width=\textwidth]{../results/figures/covariables.pdf} %may need to reduce height to make room for caption
%     \caption{\textbf{Plots expressing the relationships between the mean relative BIC scores of the four NLMs and the covariable categories.}  Mean relative BIC score here is the \textit{Total} score, as defined in Section 2.4, awarded to each model for each timeseries, averaged across each covariable category. Barplots are used for the categoric covariables, while a scatterplot with linear regression lines and standard error ribbons is used to plot the continuous incubation temperature data. The colours of the legend apply to all three plots.}
% \end{figure*}

























%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Discussion %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Discussion}

% This should attempt to tie together the results, what they indicate in a broader context, the extent to which the original aims have been satisfied and what future work is suggested.
% Return to and address the ideas raised in the introduction.

% In particular, think about:
% o What’s the main thing we know now that we didn’t know before?
% o What’s the chain of logic and results that means we know it?
% o How does this affect our -- and other scientists’ -- view of the world? What are the implications?
% o What are the implications of the intermediate steps in the chain towards the main thing?
% o What are the caveats that apply to this study? (Leave out caveats that apply to all studies.) What might be done about them? (Very important in a project write-up -- What would you do differently if you were doing the project again or had more time?)
% o What future work could build more broadly on what we’ve found?
% o A nice wrap-up, emphasising how this study in this system is of interest to people who work on other things, or other systems.










%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%% NB DO NOT DELETE!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
stuff for discussion (main project)
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
QUESTION
% hap1_afr=1      hap1_eur=0      hap1_nat=0      hap2_afr=1     hap2_eur=0     hap2_nat=0  

In example above, is it not possible the two african haplotypes are different alleles? Which would technically make it heterozygous without us knowing?
(see email 20th may for more context)

ANSWER
If you are analyzing the nucletotides, you don't know. It could be a fragment from African ancestry and be a T and a fragment from European ancestry and be a T as well. You have to look to the vcf. This applies to your second example also.
It has the problem that unadmixed admixture sources from sub-Saharan Africa have higher effective population size and therefore higher heterozygosity of nucleotides. So there will be a correlation of higher sub-Saharan ancestry and higher heterozygosity of nucleotides, and therefore a bias. However, it might be interesting to discuss how heterozygosity only is not a good indicator of assortative mating in an admixed population. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
Remember above 99pc PEL individuals are included in ref sample, hence assignment of PEL ancestry will be a bit weird - definitely a bias. I went forward with both populations, but the one with will match native very perfectly, and the one without will A. show as less native than it truly is as a population as v native ones are excluded, and B. might have a native bias in assignment, where there are similarities between two PEL individuals which may not be a general native trait but a specific PEL trait. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

For frag length histograms, 2nd peaks suggest another migration event, as one would expect it to simply be a normal distribution if only one migration event occured. Similarly, right-tailed distributions suggest constant strean of subsequent immigrants after main migration event (and vice versa). test.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Remember, ASW is Americans of Sub-Saharan African Ancestry in Oklahoma, Southwest USA, MXL is Mexican Ancestry in Los Angeles CA United States - so significant sample bias; ASW will have more african than the average US SW resident; MXL will have more European, and possibly african could have come later when in LA vs generations ago in Mexico

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




















%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Data/Code %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Data and Code Availability}

% name a data and a code (GitHub) archive from where the data and code can be obtained that will allow replication of your results. The code may be in the form of a single script file. You will be taught the principles of reproducible analyses in the R week of your coursework. If the data cannot be made available publicly (e.g., because it is yet to be formally published), or if there are some other confidentiality issues with submitting the data, speak with your course director and supervisor, and include a clear statement about why the data cannot be made available under the same Code and Data Availability header.
\subsection{Data}

1KGP Samples: https://www.internationalgenome.org/data-portal/data-collection/30x-grch38
HGDP Samples: https://www.internationalgenome.org/data-portal/data-collection/hgdp


\subsection{Code}






\newpage
\printbibliography[heading=bibintoc]
\newpage














%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Sup Material %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Supplementary Material} % * prevents numbering
\addcontentsline{toc}{section}{Supplementary Material} %add to table of contents

% You may provide Supplementary Information (SI) to provide parts of the study not directly relevant to the main narrative: detailed methods, mathematical derivations, details of computer algorithms, long tables of detailed results, and taxonomic descriptions, lists and drawings in an otherwise ecological study.
% For example, a molecular study might state in the Methods section of the main text that you extracted DNA according to a phenol/chloroform extraction protocol according to a particular reference.
% In the SI, you should then describe the steps of your lab protocol in sufficient detail that other people could reproduce this procedure by following your description.
% Similarly, you should put long tables of results in the main text (these should be in SI); only summary tables or graphs and key results of analysis should appear in the main text.
% However, the project markers are not obliged to read the SI, so the text in the main manuscript should detail everything that the marker needs to know.
% The SI should be presented as an additional document and must be concatenated to the end of the main thesis pdf file before submission (that is, a single pdf file must be submitted).
% Make sure that the SI is neatly formatted (using the same style as the main text), and that all Sections, Tables and/or Figures of the SI are appropriately cited in the main text.


% Computer Programs: If the program has been published, cite the reference, include it in the reference list and provide a brief outline of the methods it uses.
% If you are using a program or code generated for the project then a more complete description is needed in the main text.
% You should provide the code used in an appendix and consider providing a flow chart and usage notes to help interpretation.
% You should take care to define all the input variables used in the program.


\end{document}